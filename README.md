This study explores the application of various machine learning algorithms for binary classification on a dataset consisting of 10,000 entries with 10 numerical features. The dataset underwent comprehensive preprocessing, including feature scaling and outlier removal, to optimize it for model training. Three fundamental models—Perceptron, Pegasos SVM, and Pegasos Logistic Regression—were initially implemented, achieving modest accuracies. To address the limitations of these linear models, polynomial feature expansion was introduced, significantly improving accuracy. Furthermore, a Kernelized Perceptron with an RBF kernel was developed, achieving the highest accuracy of 95.50% after extensive hyperparameter tuning. This research highlights the critical importance of data preprocessing, feature engineering, and the use of advanced modeling techniques to enhance predictive performance in machine learning tasks
